{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quantization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNwz2dKfR1ctKIE4bew3TVf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peta-m175/rabbit_challenge/blob/master/deep_learning/day4/quantization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7wDVaf1uj6C"
      },
      "source": [
        "# 量子化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EG_w_VXRum23"
      },
      "source": [
        "ネットワークが大きくなると大量のパラメータが必要なり学習や推論に多くのメモリと演算処理が必要\n",
        "\n",
        "-> 通常のパラメータの64 bit 浮動小数点を32 bit など下位の精度に落とすことでメモリと演算処理の削減を行う"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4Uu1jHUTx6z"
      },
      "source": [
        "- メリット\n",
        "  - 計算の高速化\n",
        "    - 倍精度演算(64 bit)と単精度演算(32 bit)は演算性能が大きく違うため、量子化により精度を落とすことによりより多くの計算をすることができる。\n",
        "  - 省メモリ化\n",
        "    - ニューロンの重みを浮動小数点数のbit数を少なくし有効桁数を下げることで、ニューロンのメモリサイズを小さくすることができる。\n",
        "- デメリット\n",
        "  - 精度の低下\n",
        "    - ニューロンが表現できる少数の有効桁が小さくなる。\\\n",
        "      \\-\\>モデルの表現力が低下する。\n",
        "    - 実際問題、倍精度を単精度にしても精度は変わらない"
      ]
    }
  ]
}