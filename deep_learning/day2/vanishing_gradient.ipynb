{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vanishing_gradient.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMbAGKw7SGP55rrfPhx6KdN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peta-m175/rabbit_challenge/blob/master/deep_learning/day2/vanishing_gradient.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNKlHUKb4Kjr"
      },
      "source": [
        "# 勾配消失問題"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usmpVEfy4O8k"
      },
      "source": [
        "誤差逆伝播法が下位層（後半）に進んでいくに連れて、勾配がどんどん緩やかになっていく。\n",
        "\n",
        "そのため、勾配降下法による、更新では下位層のパラメータはほとんど変わらず、訓練は最適値に収束しなくなる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGVpnP7cn2H3"
      },
      "source": [
        "### 勾配消失問題のビジョン"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69BU3ZWPp9DH"
      },
      "source": [
        "シグモイド関数の最大値が0.5のため、勾配を重ねる(掛け合わせる)度、学習率の増加は小さくなる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGiotJw8qZjX"
      },
      "source": [
        "## 勾配消失の解決方"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0wRtf9JqnEf"
      },
      "source": [
        "### 活性化関数の選択"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRyr7ItGqvBw"
      },
      "source": [
        "#### Relu関数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjWFeaiKrshC"
      },
      "source": [
        "勾配消失問題の回避とスパース化に貢献することで良い成果をもたらす。\n",
        "$$\n",
        "f(x)= \\begin{cases}\n",
        "    x~~~(x>0) \\\\\n",
        "    0~~~(x\\le0)\n",
        "  \\end{cases}\n",
        "$$\n",
        "```\n",
        "def relu(x):\n",
        "  return np.maximum(0, x)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "NmCfzmhBtd-i",
        "outputId": "2ec0c800-c357-48d6-a2eb-793effa90992"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def relu(x):\n",
        "  return np.maximum(0, x)\n",
        "\n",
        "x = np.arange(-5, 6, 1)\n",
        "y = relu(x)\n",
        "plt.plot(x,y)\n",
        "plt.xlim(-6, 6)\n",
        "plt.ylim(-1, 6)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNDp_RjFqplH"
      },
      "source": [
        "### 重みの初期値設定"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5bTXqBQrGqo"
      },
      "source": [
        "#### Xavier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thIzGXkbraTx"
      },
      "source": [
        "- 初期値を設定する際の活性化関数\n",
        "  - Relu関数\n",
        "  - シグモイド（ロジスティック）関数\n",
        "  - 双曲線正接関数\n",
        "- 設定方法\n",
        "  - 重みの要素を、前の層のノード数の平方根で除算した値\n",
        "  ```\n",
        "  # Xavierの初期値\n",
        "    network['W1'] = np.random.randn(input_layer_size, hidden_layer_1_size) / (np.sqrt(input_layer_size))\n",
        "    network['W2'] = np.random.randn(hidden_layer_1_size, hidden_layer_2_size) / (np.sqrt(hidden_layer_1_size))\n",
        "    ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olhKFPeyrIrI"
      },
      "source": [
        "#### He"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFDpNiBbrQXx"
      },
      "source": [
        "- 初期値を設定する際の活性化関数\n",
        "  - Relu関数\n",
        "- 設定方法\n",
        "  - 重みの要素を、前の層のノード数の平方根で除算した値に対し√２をかけ合わせた値\n",
        "  ```\n",
        "    # Heの初期値\n",
        "    network['W1'] = np.random.randn(input_layer_size, hidden_layer_1_size) / np.sqrt(input_layer_size) * np.sqrt(2)\n",
        "    network['W2'] = np.random.randn(hidden_layer_1_size, hidden_layer_2_size) / np.sqrt(hidden_layer_1_size) * np.sqrt(2)\n",
        "  ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G885j0t8qrtH"
      },
      "source": [
        "### バッチ正規化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH2EtaShrLxZ"
      },
      "source": [
        "- ミニバッチ単位で、入力値のデータの偏りを抑制する手法\n",
        "- 2015年頃に提唱され、多くの論文で利用される。\n",
        "\n",
        "使いどころ\n",
        "- 活性化関数に値を渡す前後に、バッチ正規化の処理を孕んだ層を加える\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYROb1sfOKDd"
      },
      "source": [
        "1. \n",
        "$$\n",
        "\\mu_t =\\frac{1}{N_t}\\sum_{i=1}^{N_t}x_{ni}\n",
        "$$\n",
        "2. \n",
        "$$\n",
        "\\sigma_t^2= \\frac{1}{N_t}\\sum_{i=1}^{N_t}(x_{ni}-=mu_t)^2\n",
        "$$\n",
        "3. \n",
        "$$\n",
        "\\hat{x}_{ni}=\\frac{x_{ni}-\\mu_t}{\\sqrt{\\sigma_t^2+\\theta}}\n",
        "$$\n",
        "4. \n",
        "$$\n",
        "y_{ni}=\\gamma x_{ni}+\\beta\n",
        "$$\n",
        "- $\\mu_t$:ミニバッチ$t$全体の平均\n",
        "- $\\sigma_t^2$:ミニバッチ$t$全体の標準偏差\n",
        "- $N_t$:ミニバッチのインデックス\n",
        "- $\\hat{x}_{ni}$:0に値を近づける計算(0を中心とするセンタリング)と正規化を施した値\n",
        "- $\\gamma$:スケーリングパラメータ\n",
        "- $\\beta$:シフトパラメータ\n",
        "- $y_{ni}$:ミニバッチのインデックス値とスケーリングの積にシフトを加算した値(バッチ正規化オペレーションの出力)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js2OSPdFJP2V"
      },
      "source": [
        "## 確認テスト"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eWd8CV-JUBs"
      },
      "source": [
        "### P.13"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YirvV0SJWhG"
      },
      "source": [
        "- Q: 連鎖律の原理を使い、$\\frac{d z}{d x}$を求めよ\n",
        "$$\n",
        "z = t^2\\\\\n",
        "t = x+y\n",
        "$$\n",
        "- A:\n",
        "$$\n",
        "\\frac{d z}{d x} = 2t \\cdot 1 = 2t=2(x+y)\\\\\n",
        "\\frac{d z}{d x}=\\frac{d z}{d t}\\frac{d t}{d x}\\\\\n",
        "z=t^2 \\\\\n",
        "t=x+y\\\\\n",
        "\\frac{d z}{d t}=2t \\\\\n",
        "\\frac{d t}{d x}=1\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K8aWewkjHox"
      },
      "source": [
        "### P.20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN6sB3mNjKWh"
      },
      "source": [
        "- Q: シグモイド関数を微分した時、入力値が0の時に最大値をとる。その値として正しいものを選択肢から選べ。\n",
        "  1. 0.15\n",
        "  2. 0.25\n",
        "  3. 0.35\n",
        "  4. 0.45\n",
        "- A: 2\n",
        "\n",
        "  シグモイド関数の最大値は0.5($x=0$のとき)\n",
        "\n",
        "  シグモイド関数\n",
        "  $$\n",
        "  \\varsigma_a(x)=\\frac{1}{1+\\exp^{-u}}\n",
        "  $$\n",
        "  のため、これを微分し導関数がわかる。\n",
        "  $$\n",
        "  \\varsigma_a'(x)=\\frac{a\\exp^{-ax}}{(1+\\exp^{-ax})}=a\\varsigma_a(x)\\{1-\\varsigma_a(x)\\}\n",
        "  $$\n",
        "  ここでは標準シグモイド関数の為、$a=1$とする。\n",
        "\n",
        "  よって\n",
        "  $$\n",
        "  \\varsigma_1'(x)=(1-0.5)\\cdot 0.5 = 0.25\n",
        "  $$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TE6L1IVq4fQ"
      },
      "source": [
        "### P.28"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kscHnkyMq7Tw"
      },
      "source": [
        "- Q: 重みの初期値に0を設定すると、どのような問題が発生するか。簡潔に説明せよ。\n",
        "- A: バイアスが変動なく伝わるため、誤差の最小化のために行うパラメータのチューニングができなくなる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc2I3lrgsF3D"
      },
      "source": [
        "### P.31"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHM8cfdfsJ_L"
      },
      "source": [
        "- Q: 一般的に考えられるバッチ正規化の効果を2点挙げよ。\n",
        "- A: \n",
        "  1. 大きな学習係数が使える\n",
        "    - これまでは、学習係数を上げるとパラメータのscaleの問題によって、勾配消失・爆発する。\n",
        "      \n",
        "      伝播中パラメータのscaleに影響を受けなくなる。結果的に学習係数を上げることができ、学習の収束速度が向上する。\n",
        "  2. 正則化効果がある\n",
        "    - これまでの正則化テクニックを不要にできるという議論がある。\n",
        "      - L2正則化の必要性が下がる\n",
        "      - Dropoutの必要性が下がる\n",
        "        - Dropoutは、過学習を抑える働きがあるが学習速度が遅くなる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfA_39dYmPAA"
      },
      "source": [
        "## 演習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6_Knu4dmSug"
      },
      "source": [
        "https://colab.research.google.com/github/peta-m175/rabbit_challenge/blob/master/deep_learning/day2/exercises/2_2_2_vanishing_gradient_modified.ipynb"
      ]
    }
  ]
}